# cuda最优策略

衡量标准为每个流处理器（SM）的占用率

## 1.共享内存大小

帕斯卡 ( Pascal ) 64k

麦克斯韦尔 ( Maxwell ) 96k

## 2.寄存器个数

cuda中寄存器用于记录核函数使用时的变量个数，单个线程最大为为255.

但是启动的总线程数*变量数不得超过每个块的上限（64k）

## 3.线程/块的大小

线程少块多，线程多块少。每个SM上限32块。

## 4.线程束的个数

每个SM最多64个线程束。衡量占用率的最终决定因素。

## cuda计算原理

![image-20210609141320557](.\图片\gpu架构图.png)

# 暗通道加速项目

难点

## 内存缓存设计和边缘处理。

按照行为单元进行计算。

## bit排序

将任意一个长为2n的双调序列A分为等长的两半X和Y，将X中的元素与Y中的元素一一按原序比较，即a[i]与a[i+n] (i < n)比较，将较大者放入MAX序列，较小者放入MIN序列。则得到的MAX和MIN序列仍然是双调序列，并且MAX序列中的任意一个元素不小于MIN序列中的任意一个元素[2]。

# 立体匹配项目

代价计算

代价聚合

后处理

二次插值，左右一致性检查



cuda项目介绍：

## GPU硬件架构介绍：

GPU的核心数量不同于CPU核心，GPU核心往往具有成百上千个核心，为此为了管理便于管理核心，GPU硬件上存在若干被称为**流式处理器SM**的硬件结构用于管理GPU核心的调度。每个SM管理32个GPU核心，具有一片独立的L1内存。能够同时为16个核心提供数据。

同时GPU存在一种名为**千兆调度器**的硬件结构，这个结构将决定我们假想的线程任务具体被落实到哪个SM来执行。

**高速共享内存L2**：这是GPU内部除了显存以外唯一的一片共享内存，对于我项目来说大概为96KB。

**内存控制器：**将显卡全局显存载入L2；

以上为简要的硬件基本情况介绍；

GPU加速流程：CPU端将内存内数据通过对应接口拷贝到GPU对应显存，然后通过**内存控制器**提供的接口将全局显存上的需要高效计算数据的数据拷贝到**高速共享内存L2**中，之后**L1控制器**将自动将数据传输到对应的GPU核心中，等上述过程就绪之后。**千兆调度器**将会负责将项目程序中编写的虚拟线程去寻找物理意义上空闲的**流式处理器SM**。最终实现计算。

cuda程序的难点：

软件层面上，所有的任务以块为单位进行执行，每个块内所有的线程执行的程序都相同。单个块可以执行32-1024个线程。而每个SM最多能启动32个块共2048个线程。这就需要进行合理的分配，尽量减少无用的碎片线程产生。

需要进行**L2高速共享内存**区域的内存手工管理，所有SM都共享这片区域如果单个SM所占用过多会导致实际能够运行的SM数量减少。

同时每个具体线程所执行的函数我们称为核函数，每个线程最多只能拥有255个变量。同时每个块所能有变量个数也有上限。所以跟之前共享内存的道理一样需要合理分配。

综合以上多种角度，最终绝对效率的因素为，SM的线程利用率，达到2048线程全利用即为效率最高的设计。